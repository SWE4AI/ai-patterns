const e="042",t="Model Published as Data",i="",n="There is a simplicity-flexibility trade-off in deployment; it is required to ingest the model at runtime",s="The training process publishes a trained model to a streaming platform (i.e. Apache Kafka) which will be consumed at runtime by the application, instead of build time \u2014 eligible to subscribe for any model updates.",o=`Pre-trained: yes,
On-the-fly-predictions: yes. Maintaining the infrastructure required for this archeticutre demands much more engineering sophistication, however ML models can be updated without any applications needing to be redeployed \u2014 this is because the model can be ingested at runtime.`,a="",r=[""],c=["Deployment"],d=["113"],l={id:e,name:t,aka:i,motivation:n,solution:s,consequences:o,examples:a,related:r,categories:c,resources:d};export{i as aka,c as categories,o as consequences,l as default,a as examples,e as id,n as motivation,t as name,r as related,d as resources,s as solution};
