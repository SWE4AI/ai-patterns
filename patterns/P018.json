{
	"id": "018",
	"name": "Partial Rejection of Safety Responsibility",
	"aka": "",
	"motivation": "Recent developments in ML and DL allowed probabilistic systems with large input and output spaces to be explored in safety critical systems. This introduces safety-related challenges, such as: (1) Model complexity and opacity, (2) Dealing with probabilistic output, (3) Sensitivity to distribution shifts (4) Formal verification is impossible or not scalable and more. This safety responsibility has to be dealt with.",
	"solution": "A system decides to reject the predictions of a DL algorith or delay any decisions until it is confident enough",
	"consequences": "One can allow some uncertainty in a system, while imposing relatively low constraints on the DL algorithms used.",
	"examples": "A UAV operating at high altitudes can not\nencounter birds or similar objects. This property can easily\nbe verified by checking the altitude (where altimeters corresponds to classic safety critical systems). If such a prediction\nis given by a sensing system, the system can decide to reject\nit or take further actions (such as to trigger a fail safe mode).",
	"related": [
		"Delegation of Safety Responsibility",
		"Full Acceptance of Safety Responsibility"
	],
	"categories": [
		"Safety"
	],
	"resources": [
		"016"
	]
}