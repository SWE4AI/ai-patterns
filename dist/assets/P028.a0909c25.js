const e="028",o="Explainable Predictions",s="",t=`Goal: increase user trust. Why does a model makes a certain prediction?

Metrics (e.g. accuracy) only tell one piece of the story`,n=`some models are interpretable by design (e.g. decision trees)

complex models: use post hoc explainability (area of ongoing research): e.g. feature attributions
2 types of feature attributions:
- instance-level
- global`,a="are only as good as the models training data, quality of model and the chosen baseline",i="",c=[""],r=["ML pattern","Responsible AI"],l=["101","106"],d={id:e,name:o,aka:s,motivation:t,solution:n,consequences:a,examples:i,related:c,categories:r,resources:l};export{s as aka,r as categories,a as consequences,d as default,i as examples,e as id,t as motivation,o as name,c as related,l as resources,n as solution};
