{
	"id": "001",
	"name": "Encapsulating ML Models within Rule-based Safeguards",
	"aka": "",
	"motivation": "It is impossible to guarantee the correctness of ML model predictions, so they should not be directly used for safety- or security-related functions. Furthermore, ML models can be unstable and vulnerable to adversarial attacks, data noise, and drift.",
	"solution": "Introduce a deterministic, rule-based mechanism that decides what to do with the prediction results, e.g., based on additional quality checks.",
	"consequences": "Reduced risk for negative impacts of incorrect predictions, but a more complex architecture.",
	"examples": "",
	"related": [
		""
	],
	"categories": [
		"Security & Safety"
	],
	"resources": [
		"001",
		"012",
		"012112",
		"012113",
		"012128"
	]
}